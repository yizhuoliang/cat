{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import nmslib\n",
    "\n",
    "# Loading the transformer model\n",
    "# SentenceTransformer uses transformer models (like BERT, RoBERTa, etc.)\n",
    "# It's designed to produce sentence embeddings, i.e. a semantic representation for an entire sentence\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def create_index(embeddings):\n",
    "    \"\"\"\n",
    "    This function creates an nmslib index from the embeddings of the sentences.\n",
    "\n",
    "    :param embeddings: The sentence embeddings\n",
    "    :return: An nmslib index\n",
    "    \"\"\"\n",
    "    # Initialize a new index\n",
    "    # method='hnsw': we use HNSW (Hierarchical Navigable Small World), which is a state-of-the-art\n",
    "    # method for nearest neighbor search\n",
    "    # space='cosinesimil': we use cosine similarity as the similarity metric\n",
    "    index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "\n",
    "    # Add the sentence embeddings to the index\n",
    "    # The embeddings are efficiently stored so that the nearest neighbors to a query can be quickly computed\n",
    "    index.addDataPointBatch(embeddings)\n",
    "    \n",
    "    # Create the index\n",
    "    # 'post': 2: It determines the amount of work that should be performed during the index construction\n",
    "    index.createIndex({'post': 2}, print_progress=True)\n",
    "    return index\n",
    "\n",
    "def search(query: str, index, sentence_list, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    This function converts a query to an embedding and finds the top_k most similar sentences.\n",
    "\n",
    "    :param query: The input query\n",
    "    :param index: The nmslib index\n",
    "    :param sentence_list: The list of sentences\n",
    "    :param top_k: The number of nearest neighbors\n",
    "    :return: The top_k most similar sentences to the query\n",
    "    \"\"\"\n",
    "    # Convert the query to an embedding\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # Search for the top_k most similar sentences to the query\n",
    "    # knnQuery returns two lists: a list of indices of the nearest neighbors and a list of the corresponding distances\n",
    "    ids, distances = index.knnQuery(query_embedding, k=top_k)\n",
    "    \n",
    "    # Map the list of indices to the actual sentences and return it\n",
    "    return [sentence_list[i] for i in ids]\n",
    "\n",
    "# Assume we have a list of sentences (conversational history)\n",
    "conversational_history = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I'm fine, thank you!\",\n",
    "    \"What's your favorite color?\",\n",
    "    \"I love blue.\",\n",
    "    \"Do you like ice cream?\",\n",
    "    \"Yes, especially vanilla flavor.\",\n",
    "    # more sentences...\n",
    "]\n",
    "\n",
    "# Transform the sentences to embeddings\n",
    "# Each sentence is mapped to a high-dimensional vector\n",
    "# Semantically similar sentences will be close in this vector space\n",
    "sentence_embeddings = model.encode(conversational_history)\n",
    "\n",
    "# Convert the list of sentence embeddings to a numpy array\n",
    "# This is necessary because nmslib expects an array-like structure\n",
    "sentence_embeddings_np = np.array(sentence_embeddings)\n",
    "\n",
    "# Create the search index from the sentence embeddings\n",
    "# The index can be used to efficiently find the sentences most similar to a query\n",
    "search_index = create_index(sentence_embeddings_np)\n",
    "\n",
    "# Search for the most similar sentences to a query\n",
    "# The function will return the sentences most similar to the query\n",
    "query = \"Who likes dessert?\"\n",
    "print(search(query, search_index, conversational_history))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
