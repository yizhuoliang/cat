{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Soccer is an interesting sport\n",
      "Similarity Score: 0.6141889663426563\n",
      "\n",
      "Document: I love eating pizza\n",
      "Similarity Score: 0.0\n",
      "\n",
      "Document: The movie was great\n",
      "Similarity Score: 0.0\n",
      "\n",
      "Document: I enjoy playing soccer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "Document: Pizza is my favorite food\n",
      "Similarity Score: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/coulson/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/coulson/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample documents for the search index\n",
    "documents = [\n",
    "    \"I love eating pizza\",\n",
    "    \"The movie was great\",\n",
    "    \"I enjoy playing soccer\",\n",
    "    \"Pizza is my favorite food\",\n",
    "    \"Soccer is an interesting sport\"\n",
    "]\n",
    "\n",
    "# Preprocessing steps: tokenization and stop word removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenized_documents = [nltk.word_tokenize(doc.lower()) for doc in documents]\n",
    "filtered_documents = [[word for word in doc if word not in stop_words] for doc in tokenized_documents]\n",
    "\n",
    "# Convert documents to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([' '.join(doc) for doc in filtered_documents])\n",
    "\n",
    "# User query\n",
    "query = \"what sport do you like\"\n",
    "\n",
    "# Preprocess the query\n",
    "tokenized_query = nltk.word_tokenize(query.lower())\n",
    "filtered_query = [word for word in tokenized_query if word not in stop_words]\n",
    "\n",
    "# Convert the query to a TF-IDF vector\n",
    "query_vector = vectorizer.transform([' '.join(filtered_query)])\n",
    "\n",
    "# Compute cosine similarity between the query vector and document vectors\n",
    "cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "# Sort documents based on similarity scores\n",
    "results = [(documents[i], score) for i, score in enumerate(cosine_similarities)]\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the search results\n",
    "for result in results:\n",
    "    print(f\"Document: {result[0]}\\nSimilarity Score: {result[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load Universal Sentence Encoder\n",
    "use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "# Sample conversation records\n",
    "conversation_records = [\n",
    "    \"Sure, what specific product are you looking for?\",\n",
    "    \"I'm looking for a smartphone with a good camera.\",\n",
    "    \"We have several options available. Let me provide you with some recommendations.\"\n",
    "]\n",
    "\n",
    "# User query\n",
    "query = \"I want to buy a new phone with a great camera.\"\n",
    "\n",
    "# Preprocess the query and conversation records\n",
    "preprocessed_query = [query]\n",
    "preprocessed_records = conversation_records\n",
    "\n",
    "# Split records into smaller batches\n",
    "batch_size = 2\n",
    "record_batches = [preprocessed_records[i:i+batch_size] for i in range(0, len(preprocessed_records), batch_size)]\n",
    "\n",
    "# Encode the query and conversation records batch-wise\n",
    "query_vector = use_model(preprocessed_query)\n",
    "record_vectors = []\n",
    "\n",
    "for batch in record_batches:\n",
    "    batch_vectors = use_model(batch)\n",
    "    record_vectors.extend(batch_vectors)\n",
    "\n",
    "record_vectors = tf.concat(record_vectors, axis=0)\n",
    "\n",
    "# Compute cosine similarity between the query vector and record vectors\n",
    "cosine_similarities = cosine_similarity(query_vector, record_vectors).flatten()\n",
    "\n",
    "# Sort records based on similarity scores\n",
    "results = [(conversation_records[i], score) for i, score in enumerate(cosine_similarities)]\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the search results\n",
    "for result in results:\n",
    "    print(f\"Conversation: {result[0]}\\nSimilarity Score: {result[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
